-----------------------------------------VERSION 1------------------------------------------------------

import cv2 #Es la biblioteca openCV, que se usa para trabajar con imagenes y videos, como abrir la camara, procesar imagenes y mostrar resultados.
import mediapipe as mp #Una biblioteca de Google para realizar tareas como el reconocimiento de manos. la deteccion de rostros, entre otras.
import csv #biblioteca que maneja archivos .csv
import os

archivo_existe=os.path.exists("datos_manos_cara.csv")
file = open("datos_manos_cara.csv", mode="a", newline="") 
csv_writer=csv.writer(file) #escritor de csv, va metiendo datos al archivo, linea por linea

if not archivo_existe:
    header=[]
    for h in ('left', 'right'):
        for i in range (21):
            header += [f'{h}_hand_{i}_x', f'{h}_hand_{i}_y', f'{h}_hand_{i}_z']
    for i in range(468):
        header += [f'face_{i}_x', f'face_{i}_y', f'face_{i}_z']

    csv_writer.writerow(header)

etiqueta = input("que etiqueta esta grabando?")

mp_hands = mp.solutions.hands #esto detecta las manos
mp_face = mp.solutions.face_mesh #detecta la cara
mp_draw = mp.solutions.drawing_utils #dibuja las conexiones sobre las manos

hands = mp_hands.Hands() #Procesa cada fotograma para detectar las manos
face = mp_face.FaceMesh(max_num_faces=1) #hace que detecte solo 1 rostro
drawing_spec = mp_draw.DrawingSpec(thickness=1, circle_radius=1)

cap = cv2.VideoCapture(0) #Abre la camara, el numero 0 se refiere a la primera camara disponible en el dispositivo

while True:  #Inicia un bucle infinito
    row = []

    success, frame = cap.read() #cap.read() lee un fotograma de la camara, succes es un valor booleano que determina si la lectura fue exitosa y frame es el fotograma leido
    if not success: #si no se puede leer el fotograma
        break #el bucle se detiene

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #es para convertir el formato BGR (el que usa OpenCV, y lo cambia al RGB, el cual es el que MediaPipe usa)

    hand_results = hands.process(rgb_frame) #pasa la imagen ya en RGB a al modelo de MediaPipe para procesar las manos
    face_results = face.process(rgb_frame) #pasa la imagen ya en RGB a mediapipe para procesar la cara

    if hand_results.multi_hand_landmarks: #verifica si se identificaron manos
        for hand_landmarks in hand_results.multi_hand_landmarks: #si se detectaron mas de una mano, recorre cada mano detectada
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS) #dibuja los puntos de referencia

    if face_results.multi_face_landmarks: #verifica si se identificaron rostros
        for face_landmarks in face_results.multi_face_landmarks:  #por cada cara identificada (solo se puede identificar una ya que asi lo dije yo), va a ejecutar el siguiente codigo.
            mp_draw.draw_landmarks (
                image=frame, #dice que la imagen leida es la variable frame
                landmark_list=face_landmarks, #la lista de puntos del rostro detectado
                connections=mp_face.FACEMESH_TESSELATION, #Dibuja la red de triangulos que conecta todos los puntos en la cara
                landmark_drawing_spec=drawing_spec, #este es el como se ven los puntos
                connection_drawing_spec=drawing_spec #esto es como se ven las lineas que conectan los puntos
            )
    left_hand = [0]*63    #este segmento inicializa dos listas de 63 ceros cada una,
    right_hand = [0]*63   #significando que si no se detecta ninguna mano, se rellenara con ceros
    if hand_results.multi_hand_landmarks:
        for i, hand_landmarks in enumerate(hand_results.multi_hand_landmarks):  #enumerate the da el indice "i" y los landmark de cada mano detectada
            base = hand_landmarks.landmark[0]
            coords = []    #aca se guarda las cordenadas de  esa mano
            for landmark in hand_landmarks.landmark:  #recorre los 21 puntos de cada mano, caad punto teniendo x, y, z
                coords += [landmark.x - base.x,       #secuencia para que sea todo relativo
                           landmark.y - base.y, 
                           landmark.z - base.z
                           ]   #agrega los 3 valores a la lista coords
            
            handedness = hand_results.multi_handedness[i].classification[0].label  #determina se la mano es la izquierda o la derecha, el indice i se usa para emparejar la mano detectada con su tipo

            if handedness == 'Left': #si es la mano izquierda se guarda en left_hand
                left_hand = coords
            else:                    #si no, en right_hand
                right_hand = coords
        row += left_hand + right_hand   #despues de concatena
    
    if face_results.multi_face_landmarks:
        base = face_results.multi_face_landmarks[0].landmark[1]
        for landmark in face_results.multi_face_landmarks[0].landmark:
            row += [
                landmark.x - base.x, 
                landmark.y - base.y, 
                landmark.z - base.z
                ]
    else:
        row += [0]*1404
    
    row.append(etiqueta)

    csv_writer.writerow(row)

    cv2.imshow("Sign Language Translation", frame) #nombre de la ventana en la que se muestra todo el proceso

    if cv2.waitKey(1) & 0xFF == ord('q'): #si el usuario presiona 'q'
        break #el programa va a parar

cap.release() #libera la camara para que otros programas puedan usar despues de terminar la ejecucion
cv2.destroyAllWindows() #cierra la(s) ventana(s)
file.close()


--------------------------------------------------VERSION 1.5--------------------------------------
import cv2              # c치mara/procesar im치genes
import mediapipe as mp  # puntos de manos y cara
import csv              # manejar archivos csv
import os

mp_hands = mp.solutions.hands           #libreria detecta manos 
mp_face = mp.solutions.face_mesh        #liberia detecta cara
mp_draw = mp.solutions.drawing_utils    #libreria que dibuja los puntos y las conexiones entre otros

hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7, min_tracking_confidence=0.7)    #procesa los fotogramas var
face = mp_face.FaceMesh(max_num_faces=1)    #procesa los fotogramas var
drawing_spec = mp_draw.DrawingSpec(thickness=1, circle_radius=1) #dibuja los puntos y conexiones var

cap = cv2.VideoCapture(0) #abre la camara

grabando = False          #dependiendo de que es falso o verdadero, va a empezar a grabar la secuencia
secuencia = []            #prepara un futuro conjunto de frames, en los que se hace un gesto
etiqueta = ""             #el nombre del gesto que se esta haciendo ('hola', 'que tal')
sequence_counter = 0      #contador de cuantas veces si hizo el gesto, es como un id

print("Presiona 'e' para ingresar etiqueta del gesto.")
print("Presiona 's' para iniciar/detener grabaci칩n.")
print("Presiona 'q' para salir.")

while True:               #mientras grabar sea verdadero
    success, frame = cap.read()    #lee un frame, success es un valor booleano que determina si la leida fue exitosa, y frame es el fotograma leido, ambos son variables, que guardan un valor, este caso, frame lee el fotograma, y success dice si fue exitoso o no.
    if not success: #si no se encontro un frame
        break       #termina el ciclo

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #pasa el fotograma de BGR a RGB,colores que usa mediapipe
    hand_results = hands.process(rgb_frame) #procesa el fotograma ya cambiado
    face_results = face.process(rgb_frame)  #lo mismo pero para la cara

    # Dibuja puntos
    if hand_results.multi_hand_landmarks:   #revisa si se detectaron manos
        for hand_landmarks in hand_results.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
    if face_results.multi_face_landmarks:
        for face_landmarks in face_results.multi_face_landmarks:
            mp_draw.draw_landmarks(frame, face_landmarks, mp_face.FACEMESH_TESSELATION, drawing_spec, drawing_spec)

    # Extrae datos de landmarks
    row = []
    left_hand = [0]*63
    right_hand = [0]*63
    if hand_results.multi_hand_landmarks:
        for i, hand_landmarks in enumerate(hand_results.multi_hand_landmarks):
            base = hand_landmarks.landmark[0]
            coords = []
            for landmark in hand_landmarks.landmark:
                coords += [landmark.x - base.x, landmark.y - base.y, landmark.z - base.z]
            handedness = hand_results.multi_handedness[i].classification[0].label
            if handedness == 'Left':
                left_hand = coords
            else:
                right_hand = coords
        row += left_hand + right_hand
    if face_results.multi_face_landmarks:
        base = face_results.multi_face_landmarks[0].landmark[1]
        for landmark in face_results.multi_face_landmarks[0].landmark:
            row += [landmark.x - base.x, landmark.y - base.y, landmark.z - base.z]
    else:
        row += [0]*1404

    # Solo guardar si est치 grabando y hay etiqueta
    if grabando and etiqueta != "":
        secuencia.append(row)

    # Mostrar en pantalla
    texto_estado = "Grabando" if grabando else "Esperando"
    cv2.putText(frame, f"Estado: {texto_estado}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)    #la imagen, el estado del texto el cual cambia si esta grabando o no, la pocicion (x, y), el tipo de letra, el tamano de la letra, el color, el grosor
    cv2.putText(frame, f"Gesto: {etiqueta}", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)         #lo mismo
    cv2.imshow("Sign Language Translation", frame)      #el nombre de la ventana

    key = cv2.waitKey(1) & 0xFF #espera de manera permanente una tecla, de un solo caracter
    if key == ord('q'):
        break
    elif key == ord('e'):  # Pide etiqueta nueva
        etiqueta = input("Escribe la etiqueta del gesto que vas a grabar: ")
        print(f"Etiqueta '{etiqueta}' guardada.")
    elif key == ord('s'):  # Start/stop grabaci칩n
        if etiqueta == "":
            print("Primero ingresa la etiqueta con 'e'")
        else:
            grabando = not grabando
            if grabando:
                secuencia = []          # limpio secuencia al iniciar grabaci칩n
                sequence_counter += 1   # nuevo id de secuencia
            else:
                if len(secuencia) > 0:
                    archivo = f"{etiqueta}.csv"
                    existe = os.path.exists(archivo)
                    with open(archivo, mode='a', newline='') as f:
                        writer = csv.writer(f)
                        if not existe:
                            header = []
                            for h in ('left', 'right'):
                                for i in range(21):
                                    header += [f'{h}_hand_{i}_x', f'{h}_hand_{i}_y', f'{h}_hand_{i}_z']
                            for i in range(468):
                                header += [f'face_{i}_x', f'face_{i}_y', f'face_{i}_z']
                            header.append('sequence_id')
                            header.append('label')  # Nueva columna para la etiqueta
                            writer.writerow(header)
                        for row_data in secuencia:
                            writer.writerow(row_data + [sequence_counter, etiqueta])  # agrego id y etiqueta
                    print(f"Secuencia guardada en {archivo}, frames: {len(secuencia)}")
                secuencia = []

cap.release()
cv2.destroyAllWindows()


